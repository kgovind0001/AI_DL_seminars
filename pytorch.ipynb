{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af5ad82",
   "metadata": {},
   "source": [
    "Introduction to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4878b44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu111\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bff7a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Create numpy array \n",
    "data = [[1, 2],[3, 4]]\n",
    "np_data = np.array(data)\n",
    "\n",
    "print(np_data.shape , type(np_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d49b0",
   "metadata": {},
   "source": [
    "Tensors are similar to NumPyâ€™s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9df7e1",
   "metadata": {},
   "source": [
    "# 3 ways to create a tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821bf57",
   "metadata": {},
   "source": [
    "Directly from tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2abca2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(x_data , x_data.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc32af5",
   "metadata": {},
   "source": [
    "from another numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "425e2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x_data = torch.tensor(np_data)\n",
    "print(x_data , x_data.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508cc62",
   "metadata": {},
   "source": [
    "from another tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7e5a8c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.6336, 0.9838],\n",
      "        [0.1960, 0.6049]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2f79c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([2, 2])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# some attributes of tensor\n",
    "\n",
    "print(f\"Shape of tensor: {x_rand.shape}\")\n",
    "print(f\"Datatype of tensor: {x_rand.dtype}\")\n",
    "print(f\"Device tensor is stored on: {x_rand.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33fa87",
   "metadata": {},
   "source": [
    "## Tensor operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bf470d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0143e-01, 9.6781e-01],\n",
       "        [3.8412e-02, 1.0000e+04]], device='cuda:0')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rand*x_rand # elementwise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d89435e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5920,  0.8326],\n",
       "        [ 0.1947, -0.5064]], device='cuda:0')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rand.sin() # sine of each element of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "46ae847e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.2672,   1.9675,   0.3920, 200.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rand.add(x_rand).view(1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7457e25",
   "metadata": {},
   "source": [
    "# Why use tensor at all \n",
    "\n",
    "1. We can use GPU for computations (x50)\n",
    "2. Allows us to generate a computional graph and create gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "12ccb563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "x_rand = x_rand.to(\"cuda\") # moving tensor to gpu \n",
    "print(f\"Device tensor is stored on: {x_rand.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "18a98706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient calculation wrt to tensor: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0.6336,   0.9838],\n",
       "        [  0.1960, 100.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"gradient calculation wrt to tensor: {x_rand.requires_grad}\")\n",
    "\n",
    "x_rand[1,1] = 100 # \n",
    "x_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97d950e",
   "metadata": {},
   "source": [
    "#### Gradients wrt to scalers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1848cd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0043, dtype=torch.float64), tensor(-4., dtype=torch.float64))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(0.6, dtype=torch.float64,requires_grad = True)\n",
    "z = torch.tensor(2.6, dtype=torch.float64,requires_grad = True)\n",
    "y = torch.sin(x)*x + 0.004*x**5 - x**3\n",
    "y = y**2 - 4*z + 34\n",
    "y.backward()\n",
    "x.grad , z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7f185697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient calculation wrt to tensor: True\n",
      "tensor(15834.7197, device='cuda:0', grad_fn=<MulBackward0>) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "x_rand.requires_grad = True\n",
    "print(f\"gradient calculation wrt to tensor: {x_rand.requires_grad}\")\n",
    "\n",
    "y1 = x_rand.view(-1)*x_rand.view(4,1)\n",
    "y1 = y1.norm()\n",
    "\n",
    "y2 = x_rand.inverse()\n",
    "y = y1*y2.norm()\n",
    "print(y , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "14d2e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() # Computes the gradient of current tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fa493d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-25060.2402,     57.7631],\n",
       "        [   248.2798,    716.1440]], device='cuda:0')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rand.grad # gradients "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d1018",
   "metadata": {},
   "source": [
    "##  We have 3 components to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2ae61121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000])\n"
     ]
    }
   ],
   "source": [
    "# Source https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "# input \n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "x = torch.linspace(-np.pi, np.pi, 2000, device=device, dtype=dtype)\n",
    "print(x.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "74f52b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd99fce2f40>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfnElEQVR4nO3df4xdZ53f8ffHYzs4u916QkZR7FhJBNbCDF0l7V23FdVqiydgVlWc7bLbhHHWKaAoGVF2i3ZLKFJRwyKFIjVRK8baFLKEeERgQ1FcLSjEJpR2S9hcbwPEzoa4RigeBzKb2NsiG/zr2z/OmeV6PDPnuXPP/XHu+bykq7nn3Ofc+4x/nO99nu/zQxGBmZnV15p+V8DMzPrLgcDMrOYcCMzMas6BwMys5hwIzMxqbm2/K7AaV155ZVx33XX9roaZWaUcPHjwryNibPH5SgaC6667jmaz2e9qmJlViqQfLnXeXUNmZjXnQGBmVnMOBGZmNedAYGZWcw4EZmY1V0ogkPSQpFckPbfM65L0nyQdkfRdSX+/5bXdkl7MH7vLqI+ZDaCJCZDSHtPT/a5trZTVIvgssGOF198JbM0fdwJ7ACRdAXwU+IfANuCjkkZLqpOZ9dPo6MU398OH06/ds+fiaycmuldPKycQRMQ3gddWKLIT+FxkngY2SroaeAfwZES8FhEngCdZOaCY2SCbnPz5zfvkyfLe9/Dh7D3XrIHZ2fLe14De5Qg2Ay+1HB/Lzy13/hKS7pTUlNScn5/vWkXNbBUWun0OHOju50TArl3uPipZZZLFEfFgRDQiojE2dskMaTPrh4UWQDvdPmXZswdGRnr/uUOoV0tMzAFbWo6vyc/NAb++6Pw3elQnM+vEyAhcuNDfOly4kAWiTZtgbq6/damwXrUI9gG/m48e+kfA30TEy8ATwNsljeZJ4rfn58xsUC20AvodBFodP57VyfmDVSlr+OjngW8BvyzpmKT3SrpL0l15ka8AR4EjwH8BpgEi4jXgY8Az+ePe/JyZDaKRkfLyAHffnfX5R8D4eDnvuWuXRxitgqq4eX2j0QivPmrWQ7Oz2U12tSR45BGYmkorPznZWcBZtw7OnFn99UNK0sGIaCw+X8llqM2shzq5KW/fDvv3t39d6zWbN2ddP+04ezYLPhX8otsPlRk1ZGZ9MDGxuiCw0O2zmiCw2Nzc6ruPnDdI4haBmS1tdLT9SWHj43DoUHfqs/C+69dn3/hT7doFf/7nMDPTnXoNAbcIzOxSl1/efhCI6F4QaHXmTNbiaMeePZ6AtgIHAjO72OWXw+nT6eXHx3vfFz8zk33mmjZuYQ4Gy3IgMLOfazcI7N3bm1bAcs6fzyaTpXIwWJIDgZllRkfbCwIR6cNBu2luLgtIqRwMLuFAYGbZEM3UnMCaNYM3LHNqqr067dnj0UQtHAjM6m5yMn2c/oYNWXfMoGonGHQyQW7IOBCY1dn0dPo8gY0b4dSp7tanDO0EA6l79agQBwKzupqdzbpIUmzcCCdOdLc+ZWonGHgpawcCs9pK7RqpWhBYkBoMLlzIEuU15kBgVkep34I3bKhmEFiQGgxOnsxyJTXlQGBWN6OjaXsJrFlTjZxAkdRgcOBAbUcSORCY1cnkZPow0UEeHdSu1GBQ05FEDgRmdTE7mz5CaNDmCZQhdX2i9eu7W48BVNYOZTskvSDpiKR7lnj9fknP5o/vSzrZ8tr5ltf2lVEfM1tC6rfddmbpVsnMTNpyFGfP1m6Xs46XoZY0AnwKuAk4BjwjaV9EHF4oExH/uqX8vwJubHmL0xFxQ6f1MLMVXH55Wrm77x6MZSO6ZW4ubT2lw4ezFtQw/1m0KKNFsA04EhFHI+IM8Ciwc4XytwGfL+FzzSzF5GTaGkLj4/VYsz81AV6jfEEZgWAz8FLL8bH83CUkXQtcD3y95fTrJDUlPS3pluU+RNKdebnm/Px8CdU2q4mUvMCGDf1dRbTXUru/UltSFdfrZPGtwGMR0Toc4dp8M+V3Aw9IesNSF0bEgxHRiIjG2NhYL+pqVn2pic9hGCbajqmptOTx6dO1WKm0jEAwB2xpOb4mP7eUW1nULRQRc/nPo8A3uDh/YGarNTGRtqXjsCaHi6Qmj1OX4aiwMgLBM8BWSddLWk92s79k9I+kNwGjwLdazo1Kuix/fiXwVuDw4mvNrE2zs1nCs8j27bVJiC5pbi5tl7MhH1LacSCIiHPA+4EngOeBL0bEIUn3Srq5peitwKMRFw1QfjPQlPQd4CngvtbRRma2SrffXlxm40bYv7/7dRl0KRPnzp4d6iUoFBWcONJoNKLZbPa7GmaDaWIirTVQwf/7XTM9ndYFVPE/M0kH85zsRTyz2GyYpHYJpc6yrYuZmWzkVJEh7SJyIDAbJildQps21WO+QLtSRk4NaReRA4HZsJiYSOu6mFtuUJ8ljaBKXa+pQhwIzIaBu4TKMTWVNqR0yCaaORCYDQN3CZUnpcV0+vRQdRE5EJhV3fS0u4TKVrMuIgcCs6pLGfboLqH2pHYRbV5yWbXKcSAwq7KUdfPdJbQ6KS2o48eHYntLBwKzqkpNELtLaPVSWlJDsFy1A4FZVaUkiN0l1JmZmWwpjiIVTxw7EJhVUWqC2F1CnTtxorhMxRPHDgRmVZSSIK7r8tLdsH17cZkK73PsQGBWNSkjVcbH6728dNn27wdp5TIL+xxXkAOBWZXMzmYjVYrUadvJXnnkkeIyFU0cOxCYVcnu3cVlnCDujqkpWLu2uFwFt7Z0IDCriunp4k1UNm50gribPvvZ4jIV3NqylEAgaYekFyQdkXTPEq/fIWle0rP5430tr+2W9GL+SPi6Y1ZTKTeYlBEutnpTU1n+pUjFhpMmtHNWJmkE+BRwE3AMeEbSviW2nPxCRLx/0bVXAB8FGkAAB/Nr/a/ZrFXKjSVlZIt17tCh4sRxxYaTltEi2AYciYijEXEGeBTYmXjtO4AnI+K1/Ob/JLCjhDqZDZeUG4v3H+6dlDxMhdYhKiMQbAZeajk+lp9b7LckfVfSY5K2tHktku6U1JTUnJ+fL6HaZhWRMj7dCeLeSplxXKF1iHqVLP5vwHUR8Stk3/ofbvcNIuLBiGhERGNsbKz0CpoNpNT1hJwg7r2UfExFhpOWEQjmgC0tx9fk5/5WRLwaET/LDz8N/IPUa81q7Y47ist4BnH/pCSOKzCctIxA8AywVdL1ktYDtwL7WgtIurrl8Gbg+fz5E8DbJY1KGgXenp8zs9lZOHdu5TIjI55B3E8pE/cqMJy040AQEeeA95PdwJ8HvhgRhyTdK+nmvNgHJB2S9B3gA8Ad+bWvAR8jCybPAPfm58wsZfLYw233slrZUvIzA94qUKSsYDhgGo1GNJvNflfDrHump4u/SY6PeymJQVE0nBTSVovtMkkHI6Kx+LxnFpsNopTuBAeBwZHSKhjgSWYOBGaDJqUbwZPHBkvKqK0BnmTmQGA2aFJaA548Nngq3CpwIDAbJCk3Ck8eG0wzM9korpUMaKvAgcBskKTcKDx5bHCljOIawJ3MHAjMBoVbA9WXsmdBykzxHnMgMBsURa0Bya2BKkjZs2DAFqRzIDAbBCmtgZStEq3/UvYsGLAF6TyhzGwQFE1IGhkpXm7CBkvR36kEFy70pi5/+5GeUGY2mFKSh15KonqK5npEDEyrwC0Cs35za2B4DdjfrVsEZoPIrYHhVjTK6/z5gWgVOBCY9UvKpjPj415muspSRnndfnv361HAgcCsX973vuIyXliu+opaBRF9X6bagcCsX37605Vf98JywyGlVdDnzWtKCQSSdkh6QdIRSfcs8foHJR3ON68/IOnaltfOS3o2f+xbfK3ZUEqZUOSF5YZHSlDvY66g40AgaQT4FPBOYBy4TdLi2RT/G2jkm9c/BvyHltdOR8QN+eNmzIbd7Gw2oWglbg0Ml5Sg3seN7stoEWwDjkTE0Yg4AzwK7GwtEBFPRcSp/PBpsk3qzeopZUN6twaGzwBvaVlGINgMvNRyfCw/t5z3Al9tOX6dpKakpyXdstxFku7MyzXn5+c7q7FZv6RsSO/WwHAa4FxBT5PFknYBDeCTLaevzSc4vBt4QNIblro2Ih6MiEZENMbGxnpQW7MuSBkp5NbA8EppFfQhV1BGIJgDtrQcX5Ofu4ikSeAjwM0R8bOF8xExl/88CnwDuLGEOpkNpqKRQl5merjNzBTPNu5DrqCMQPAMsFXS9ZLWA7cCF43+kXQj8MdkQeCVlvOjki7Ln18JvBUYvMW6zcqQMlLIy0wPv5RVZHucK+g4EETEOeD9wBPA88AXI+KQpHslLYwC+iTwi8CfLhom+magKek7wFPAfRHhQGDDxyOFbEHKTPEe5wq86JxZL2zYUNwtVMH/i7ZK09PFN/u77y69hehF58z6ybOIrVVKrqCHrQIHArNu8yxiW0pKrqBHI4gcCMy6KSU34JFC9ZSSK+jRyqQOBGbdlDJvwCOF6mtAViZ1IDDrJucGbCUDMtvYgcCsW5wbsBQDMNvYgcCsG5wbsFQDsIuZA4FZNzg3YO3oc67AgcCsG5wbsHb0OVfgQGBWNucGbDX6mCtwIDArk3MDtlp9zBU4EJiVybkB60SfcgUOBGZlcm7AOtGnXIEDgVlZJieLyzg3YEX6kCtwIDAry4EDK7/u3IClSGkVvOc9pX6kA4FZGVJaA84NWKqiLw1nzpT6caUEAkk7JL0g6Yike5Z4/TJJX8hf/7ak61pe+3B+/gVJ7yijPkuanoa1a7M1wNeu7flWcDbkiloDzg1YO1K+NExMlPZxHQcCSSPAp4B3AuPAbZLGFxV7L3AiIt4I3A98Ir92nGyP4wlgBzCTv1+5FnYDOn8+Oz5/PjtO+RZnVsS5AeuGolbB4fJ29S2jRbANOBIRRyPiDPAosHNRmZ3Aw/nzx4DtkpSffzQifhYRPwCO5O9XruWy7AcO9GzjBxtiRa2B8cXfi8wS9LArsYxAsBl4qeX4WH5uyTL5Zvd/A7w+8VoAJN0pqSmpOT8/X0K1cz3a+MGGVEpr4NCh7tfDhlOPuhQrkyyOiAcjohERjbGxsTLf2PkCWz3nBqybetSlWEYgmAO2tBxfk59bsoyktcDfBV5NvLZzA7RJtA0R5wasF5bLFZQ4HLmMQPAMsFXS9ZLWkyV/9y0qsw/YnT9/F/D1iIj8/K35qKLrga3AX5RQp4vddVdxGecKrF3ODVgvzMxkN/2RfBzNyEh2XGIOQdn9uMM3kX4DeAAYAR6KiI9LuhdoRsQ+Sa8DHgFuBF4Dbo2Io/m1HwHeA5wDfj8ivlr0eY1GI5rNZruVXPn1kRE4d66997T6mpwsDgQl/N8yK5OkgxHRuOR8GYGg11YVCBaGkK5k716Ymlp9xaw+ir5YbN/ubiEbOMsFgsokizs2ANvB2ZBwbsCGTH0CAaQt8epcgRUp6hJav7439TArSb0CQUqrYPfu4jJWXymtgYce6n49zEpUr0AAxa2C8+fdKrDlpYwUcp7JKqZ+gcC5AlutlImHnkVsFVS/QADOFdjqFI06c27AKqqegcC5AmuXcwM2xOoZCMC5AmtPUW5gZMS5Aaus+gYC5wosVUpu4OGHi8uYDaj6BgJwrsDSFOUG3Bqwiqt3IOjDJtFWMSm5AbcGrOLqHQig55tEW8U4N2A14ECQ0irYvOSmaTbsnBuwmnAggOJWwfHjzhXUkXMDVhMOBOB5BXYp5wasRhwIFhTtLet5BfXi3IDVSEeBQNIVkp6U9GL+c3SJMjdI+pakQ5K+K+lftLz2WUk/kPRs/rihk/p0JGX9eLcK6sG5AauZTlsE9wAHImIrcCA/XuwU8LsRMQHsAB6QtLHl9T+MiBvyx7Md1qcznm1sUJwb2LTJrQEbKp0Ggp3Awlejh4FbFheIiO9HxIv58+PAK8BYh5/bHZ5tbCmtgbm57tfDrIc6DQRXRcTL+fMfAVetVFjSNmA98H9aTn887zK6X9JlK1x7p6SmpOb8/HyH1V5BUa7As42Hm1cYtRoqDASS9kt6bonHztZyERFArPA+VwOPAP8yIi7kpz8MvAn4VeAK4EPLXR8RD0ZEIyIaY2NdbFCk5ArcKhhOXmHUaqowEETEZES8ZYnH48CP8xv8wo3+laXeQ9IvAX8GfCQinm5575cj8zPgT4BtZfxSHUtZgyilC8GqpWikkOTcgA2lTruG9gELQ2l2A48vLiBpPfBl4HMR8dii1xaCiMjyC891WJ9ypOQKiroQrFpSWgOPPNL9epj1QaeB4D7gJkkvApP5MZIakj6dl/kd4NeAO5YYJjor6XvA94ArgT/qsD7lKWoVgHMFw8TzBqzGlHXtV0uj0Yhms9n9D5KKX79wYeUyNvgmJ4sDwd69DgRWeZIORkRj8XnPLF6J9yuoB7cGrOYcCFaSkivYtav79bDumZgoLuNZxDbkHAiKpOQKPIKommZn4fDhlcuMj7s1YEPPOYIURbkCyLqJrFrWrYNz51Yu479XGyLOEXTCrYLhMztbHATGx3tTF7M+c4sg1Zo1xd8OK/hnWVtuDVgNuUXQqZTJRCmTkqz/UloDRWtOmQ0RtwjasXZtthT1Sir451k7/nu0mnKLoAwpwwhThiNa/0xPFwcBtwasZhwI2jE1lW1KspLDhz3JbJClrBGVsgKt2RBxIGhXyqYk3tJyMKWM7HJrwGrIgWA1ioYVekvLweTWgNmSHAhW49Ch4jJuFQyWlBFdKfNFzIaQA8FqFXUhuFUwWIoWloO0taXMhpADwWqldCF4QbrBkDKSy60Bq7GOAoGkKyQ9KenF/OfoMuXOt2xKs6/l/PWSvi3piKQv5LuZVUdKYtFLT/RXysJyklsDVmudtgjuAQ5ExFbgQH68lNMRcUP+uLnl/CeA+yPijcAJ4L0d1qe3UloF3tKyv1JyNd6C0mqu00CwE1iYZfUw2b7DSfJ9it8GLOxj3Nb1AyOlVeBJZv0xO1s8eWzTJi8zbbXXaSC4KiJezp//CLhqmXKvk9SU9LSkhZv964GTEbGw6MsxYPNyHyTpzvw9mvPz8x1Wu0T79xcvU+1JZv1x++3FZVLmhZgNucJAIGm/pOeWeOxsLRfZokXLLdBybb6+xbuBByS9od2KRsSDEdGIiMbY2Fi7l3dXSteCh5P21vR08XpBnjxmBiQEgoiYjIi3LPF4HPixpKsB8p+vLPMec/nPo8A3gBuBV4GNktbmxa4Bqvn1bGoq29d2JR5O2luePGaWrNOuoX3Awlfd3cDjiwtIGpV0Wf78SuCtwOG8BfEU8K6Vrq+MlAXpPJy0Nzxc1KwtnQaC+4CbJL0ITObHSGpI+nRe5s1AU9J3yG7890XEwni+DwEflHSELGfwmQ7r0z9TU2k7WnnPgu4rGi4KHi5q1mJtcZHlRcSrwCUdrRHRBN6XP/9fwN9b5vqjwLZO6jBQDh0qThynzHC11RtdcirLxdwaMLuIZxaXLSUBuXnZwVHWielpOHly5TIbN7o1YLaIA0HZUoaTHj/uxHE3pCSIT5zofj3MKsaBoBtShpM6cVyulASxh4uaLcmBoBtSdjIDJ47LkrKeEHi4qNkyHAi6JWXGqhPH5UiZQewEsdmyHAi6KaUrImWUiy1vcrJ4BjE4QWy2AgeCbkpJHJ886aWqV2t2Nq1VtXdv9+tiVmEOBN2Wkjj2UtWrk9IlND7u1UXNCjgQdFtq4thdRO1JWVQO0vaXNqs5B4JeSEkcu4uoPSmtKCeIzZI4EPRKyk3JXURpUlpPnkFslsyBoFdmZooTx+DlJ4qkLCMBnkFs1gYHgl5KSRx7+YmVuUvIrHQOBL00NZU2t8DLTyzt8svTyrlLyKwtDgS9ljK3ADyKaLGJCTh9uric5wyYtc2BoB9SuohOnvRaRAtS1xLavt1zBsxWoaNAIOkKSU9KejH/ecnXWEn/VNKzLY+fSrolf+2zkn7Q8toNndSnMlJ3MztwwPkCSOsq27DBi8qZrVKnLYJ7gAMRsRU4kB9fJCKeiogbIuIG4G3AKeBrLUX+cOH1iHi2w/pUx6FDsG5dcbm65wtSu8hOnepuPcyGWKeBYCewsGv7w8AtBeXfBXw1Ivy/FuDMmbRyqUnSYZM6VNSjhMw60mkguCoiXs6f/wi4qqD8rcDnF537uKTvSrpf0mXLXSjpTklNSc35+fkOqjxgUkYRnT6dtvHKsEkZKuqJY2YdKwwEkvZLem6Jx87WchERwLKLv0i6mmwT+ydaTn8YeBPwq8AVwIeWuz4iHoyIRkQ0xsbGiqpdHfv3Z/3bRQ4frle+IGVkFXjimFkJ1hYViIhlh65I+rGkqyPi5fxG/8oKb/U7wJcj4mzLey+0Jn4m6U+AP0is93A5dSrtxrdrVz1Gxaxfn1bOQ0XNStFp19A+YHf+fDfw+Aplb2NRt1AePJAksvzCcx3Wp7pSb2ojI92tR79t3gxnzxaX8/LSZqXpNBDcB9wk6UVgMj9GUkPSpxcKSboO2AL890XXz0r6HvA94ErgjzqsT3Wlzjq+cGF4J5tNTmZLbBRZt87LS5uVSJGypvuAaTQa0Ww2+12N7hgdTRspMz4+XDfD6en01Vcr+G/WbBBIOhgRjcXnPbN40Jw4AWsS/loOHx6emcezs+lBwHkBs9I5EAyi8+fTyh04MByb2aROmvMSEmZd4UAwqFInSe3ZU+1gkDpMdNMmLyFh1iUOBINqZiZtr2OobjBIDQLr1qVt92lmq+JAMMjm5tImm0H1gkFqEID0pTjMbFUcCAbdqVNpyWOoTjBoJwh4hJBZ1zkQVEFq8hiyYDCoo4lmZx0EzAaQA0FVtHNTPHAgm6E7SCYn21tS28NEzXqmcK0hGyAR6d+ojx/P1uwZhP71zZvTZgwvuPtuDxM16yG3CKqmnZbB2bNZ4OjnqqXr17cfBLystFlPORBUUbt957t29X4/g+npLAilLCC3wEHArC/cNVRV7XQTQbYkhZT1vXe72+Xyy7PNdNrhIGDWN24RVNlqRtXs2tW91UsnJrJg024Q2LvXQcCsj9wiqLqIrB++nS6YkyezG/bGjeXs8DUxkbU4VsNDRM36zi2CYXDmTPpyFK0WAoLU/kS0hTkB0uqCwLp1DgJmA8KBYFjMzaUvVLeUPXt+fmNfs2bpkUajoz8v086cgMU2bRqMYa1mBnQYCCT9tqRDki5IumSzg5ZyOyS9IOmIpHtazl8v6dv5+S9IStys1pY0M1POt+yI7Ea/cNNfeKRsmFPk7ru9gJzZgOm0RfAc8M+Bby5XQNII8CngncA4cJuk8fzlTwD3R8QbgRPAezusj0F2Ix8fLy7XSxs3ZvVyUths4HQUCCLi+Yh4oaDYNuBIRByNiDPAo8DOfMP6twGP5eUeJtvA3spw6FB2401dvbSb9u4tJyltZl3RixzBZuClluNj+bnXAycj4tyi80uSdKekpqTm/Px81yo7dE6d6t+6Pdu3Z8HIy0WYDbTCQCBpv6Tnlnjs7EUFF0TEgxHRiIjG2NhYLz+6+qamshtyr1oICwHAO4qZVULhPIKI6HRN4zlgS8vxNfm5V4GNktbmrYKF89ZNp05lPzsZ+7+UTZucBDarqF50DT0DbM1HCK0HbgX2RUQATwHvysvtBh7vQX0Mfp5DWHi0Ow9hw4aLr3cQMKusToeP/qakY8A/Bv5M0hP5+U2SvgKQf9t/P/AE8DzwxYg4lL/Fh4APSjpCljP4TCf1sQ7MzV18Yy96LLQszKzyFBWc3dloNKLZbPa7GmZmlSLpYERcMufLM4vNzGrOgcDMrOYcCMzMas6BwMys5iqZLJY0D/ywC299JfDXXXjfXql6/aH6v0PV6w/V/x2qXn/o3u9wbURcMiO3koGgWyQ1l8qoV0XV6w/V/x2qXn+o/u9Q9fpD738Hdw2ZmdWcA4GZWc05EFzswX5XoENVrz9U/3eoev2h+r9D1esPPf4dnCMwM6s5twjMzGrOgcDMrOYcCBaR9DFJ35X0rKSvSWpzfeb+kvRJSX+V/w5flrSx33Vql6TflnRI0gVJlRkGKGmHpBckHZF0T7/r0y5JD0l6RdJz/a7LakjaIukpSYfzfz+/1+86tUPS6yT9haTv5PX/9z37bOcILibplyLi/+bPPwCMR8Rdfa5WMklvB74eEeckfQIgIj7U52q1RdKbgQvAHwN/EBEDv9SspBHg+8BNZNuuPgPcFhEl7v7TXZJ+DfgJ8LmIeEu/69MuSVcDV0fEX0r6O8BB4Jaq/B3k+7j/QkT8RNI64H8CvxcRT3f7s90iWGQhCOR+AahUpIyIr7XsA/002c5vlRIRz0fEC/2uR5u2AUci4mhEnAEeBXq6nWunIuKbwGv9rsdqRcTLEfGX+fP/R7b/ybL7oA+ayPwkP1yXP3py/3EgWIKkj0t6CZgC/l2/69OB9wBf7XclamIz8FLL8TEqdBMaNpKuA24Evt3fmrRH0oikZ4FXgCcjoif1r2UgkLRf0nNLPHYCRMRHImILMEu2u9pAKap/XuYjwDmy32HgpPwOZqsh6ReBLwG/v6iFP/Ai4nxE3EDWkt8mqSdddIWb1w+jiJhMLDoLfAX4aBer07ai+ku6A/hnwPYY0CRQG38HVTEHbGk5viY/Zz2U961/CZiNiP/a7/qsVkSclPQUsAPoevK+li2ClUja2nK4E/irftVlNSTtAP4NcHNEeGPh3nkG2CrpeknrgVuBfX2uU63kydbPAM9HxH/sd33aJWlsYZSfpA1kAw96cv/xqKFFJH0J+GWyUSs/BO6KiMp8s5N0BLgMeDU/9XSVRj0BSPpN4D8DY8BJ4NmIeEd/a1VM0m8ADwAjwEMR8fE+V6ktkj4P/DrZEsg/Bj4aEZ/pa6XaIOmfAP8D+B7Z/1+AfxsRX+lfrdJJ+hXgYbJ/P2uAL0bEvT35bAcCM7N6c9eQmVnNORCYmdWcA4GZWc05EJiZ1ZwDgZlZzTkQmJnVnAOBmVnN/X/SkME6QNLedQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output \n",
    "\n",
    "y = x.sin() # sin of each element\n",
    "\n",
    "plt.plot(x,y,\"ro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf1192b",
   "metadata": {},
   "source": [
    "objective is to define a model to represent such data. In most cases we dont know the output functions. The model should be able to give us the output given an input. \n",
    "\n",
    "##### How do we know if it is the right model \n",
    "To measure the quality of model, we have to define a value such that it is lowest when we get to the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of models \n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\")  # Uncomment this to run on GPU\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "# By default, requires_grad=False, which indicates that we do not need to\n",
    "# compute gradients with respect to these Tensors during the backward pass.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Create random Tensors for weights. For a third order polynomial, we need\n",
    "# 4 weights: y = a + b x + c x^2 + d x^3\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "a = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y using operations on Tensors.\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
    "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e722a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7fd99f354a50>\n",
      "Result: y = -0.4730863571166992 + 0.1815604269504547 x + -0.31515631079673767 x^2 + 0.19463685154914856 x^3\n"
     ]
    }
   ],
   "source": [
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-np.pi, np.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# For this example, the output y is a linear function of (x, x^2, x^3), so\n",
    "# we can consider it as a linear layer neural network. Let's prepare the\n",
    "# tensor (x, x^2, x^3).\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "# In the above code, x.unsqueeze(-1) has shape (2000, 1), and p has shape\n",
    "# (3,), for this case, broadcasting semantics will apply to obtain a tensor\n",
    "# of shape (2000, 3) \n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. The Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "# The Flatten layer flatens the output of the linear layer to a 1D tensor,\n",
    "# to match the shape of `y`.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(1):\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Tensor of input data to the Module and it produces\n",
    "    # a Tensor of output data.\n",
    "    y_pred = model(xx)\n",
    "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "    # values of y, and the loss function returns a Tensor containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "    # we can access its gradients like we did before.\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "# You can access the first layer of `model` like accessing the first item of a list\n",
    "linear_layer = model[0]\n",
    "\n",
    "# For linear layer, its parameters are stored as `weight` and `bias`.\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef0f40",
   "metadata": {},
   "source": [
    "Sources \n",
    "\n",
    "https://www.javatpoint.com/pytorch-vs-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4961180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
